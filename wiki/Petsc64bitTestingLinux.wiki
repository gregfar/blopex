#summary BLOPEX Petsc 64bit testing on Linux
<wiki:toc max_depth="1" />

= Introduction =

How to test BLOPEX under Beta version of Petsc on Linux with Petsc configured for 64bit integers.

In this wiki we describe in detail a test with Petsc configured real numbers with side comments when this differs with complex number testing.

Refer to wiki "CommentsOnPetscTesting" for a more technical discussion on how Blopex is setup in Petsc.  

= Setup Petsc =  

To use blopex_solve_double or blopex_solve_complex using the 
Beta release of Petsc first download the development version from 
the Petsc website at ftp://info.mcs.anl.gov/pub/petsc-dev.tar.gz .
 

To install files issue command:
{{{
>> gunzip -c petsc-dev.tar.gz | tar -xof -
}}}
This creates files in directory petsc-dev.  

Download the blopex_petsc_interface.tar.gz and blopex_petsc_abstract.tar.gz from the Blopex Google Code site http://code.google.com/p/blopex and then move them to your home directory.

blopex_petsc_interface.tar.gz contains the changes to the blopex interface which is distributed as part of Petsc.  Assuming you are in your home directory, install as follows:
{{{
>> cp blopex_petsc_interface.tar.gz petsc-dev/src/contrib/blopex/
>> cd petsc-dev/src/contrib/blopex
>> tar -zxvg blopex_petsc_interface.tar.gz
}}}

Configuration in Petsc is controlled via python scripts. The script petsc-dev/config/PETSc/packages/blopex.py contains flags to control configuration when the --download-blopex option is used.  It contains the following line (about line 15)
`self.complex    = 0`.

This specifies that the blopex interface is not defined for Petsc scalar type complex.
Edit blopex.py and change this to `self.complex    = 1`.

Without this change configuration will give the error _"cannot use blopex with complex numbers it is not coded for this capability"_.

An additional change to blopex.py is needed to support 64bit integers.  After the `self.complex = 1` line; add the following line `self.requires32bitint = 0`.  Which means that blopex is coded to support 64bit integers.


Configure Petsc as follows:
{{{
>> ./config/configure.py --with-shared --with-debugging=1 --download-blopex=../blopex_petsc_abstract.tar.gz --with-64-bit-indices
}}}

Petsc runs with either double or complex objects but not both.  
To test the blopex routines for complex configure Petsc with the 
option --with-scalar-type=complex. 

Now two environment variables must be setup:
{{{
>> PETSC_DIR=/home/grads/dmccuan/petsc-dev
>> export PETSC_DIR
>> PETSC_ARCH=linux-gnu-c-debug
>> export PETSC_ARCH
}}}
We will also need these set when compiling the blopex_petsc interface and drivers.
To avoid setting everytime you logon you can put them in your .bashrc 
file as follows:
{{{
export PETSC_DIR=/home/grads/dmccuan/petsc-dev
export PETSC_ARCH=linux-gnu-c-debug
}}}

After configuration is finished issue the command
{{{
>> make all test
}}}
= Setup blopex_petsc =  
 
Now create executables for the blopex drivers 
{{{
>> cd petsc-dev/src/contrib/blopex/driver
>> make driver
>> cd ../driver_fiedler
>> make driver_fiedler
}}}

= Execution of Tests =

There are two test drivers located in subdirectories of blopex_petsc:
driver and driver_fiedler.  The executables for these are in directories
petsc_dir/src/contrib/blopex/driver and petsc_dir/src/contrib/blopex/driver_fiedler.

driver builds a 7pt laplacian for solution and calls either lobpcg_solve_complex 
if Petsc is configured for complex (this is controlled by the PETSC_USE_COMPLEX preprocessor variable) or lobpcg_solve_double if Petsc is configured for real (double). 

Both the Blopex abstract and interface code use the "PetscInt" type to determine how to define integers.  This forces the Blopex interger type to always match what is in Petsc. 


To execute driver:
{{{
>> mpirun -np 2 ./driver -n_eigs 3 -itr 20 
or 
>> ./driver -n_eigs 3 -itr 20
}}}

This gives the following results:
{{{
Partitioning: 1 1 1
Preconditioner setup, seconds: 0.000369

Solving standard eigenvalue problem with preconditioning

block size 10

No constraints


Initial Max. Residual   2.41101765193731e+00
Iteration 1     bsize 10        maxres   1.47485155706695e+00
Iteration 2     bsize 10        maxres   5.76499070872537e-01
Iteration 3     bsize 10        maxres   3.06659255730571e-01
Iteration 4     bsize 10        maxres   2.00635934430889e-01
Iteration 5     bsize 10        maxres   6.38690964763992e-02
Iteration 6     bsize 10        maxres   2.04031509081778e-02
Iteration 7     bsize 10        maxres   1.02958167235834e-02
Iteration 8     bsize 9         maxres   3.57149267532509e-03
Iteration 9     bsize 8         maxres   1.13980591096821e-03
Iteration 10    bsize 6         maxres   4.15729900972210e-04
Iteration 11    bsize 6         maxres   1.64977271895793e-04
Iteration 12    bsize 5         maxres   5.68823837427636e-05
Iteration 13    bsize 3         maxres   2.12576562467706e-05
Iteration 14    bsize 3         maxres   7.60612793341467e-06
Iteration 15    bsize 3         maxres   3.27324391450688e-06
Iteration 16    bsize 2         maxres   1.73049728975516e-06
Iteration 17    bsize 1         maxres   9.63758146551376e-07

Eigenvalue lambda       Residual              
  2.43042158313016e-01    7.85460552428888e-08
  4.79521039879645e-01    5.38143072677682e-07
  4.79521039879654e-01    4.18818869908062e-07
  4.79521039879684e-01    4.23232402359408e-07
  7.15999921446316e-01    8.92081907089266e-07
  7.15999921446375e-01    7.47752020201913e-07
  7.15999921446505e-01    8.79103766081576e-07
  8.52306637651430e-01    6.91831240708695e-07
  8.52306637651604e-01    5.47008725220135e-07
  8.52306637652249e-01    9.63758146551376e-07

17 iterations
Solution process, seconds: 2.897029e-01
}}}

driver_fiedler accepts as input matrices in Petsc format.  These matrices must be setup for either 32bit or 64bit arithematic.  The test matrices are setup for double (real) or complex and for 32bit or 64bit.  The 64bit version have a file name containing "_64"`. 

For example:
{{{
>> ./driver_fiedler -matrix DL-matrix-double_64.petsc -n_eigs 3 -itr 200
}}}

This gives the following results:
{{{
Preconditioner setup, seconds: 0.002955

Solving standard eigenvalue problem with preconditioning

block size 3

1 constraint


Initial Max. Residual   9.29703885936090e-01
Iteration 1     bsize 3         maxres   8.08364838024446e-03
Iteration 2     bsize 3         maxres   3.54278978281592e-03
Iteration 3     bsize 3         maxres   5.26702389967756e-04
Iteration 4     bsize 3         maxres   3.87008818770373e-04
.................
Iteration 197   bsize 3         maxres   3.34025396810235e-06
Iteration 198   bsize 3         maxres   3.35960348089173e-06
Iteration 199   bsize 3         maxres   3.39105815089645e-06
Iteration 200   bsize 3         maxres   3.38848721913166e-06

Eigenvalue lambda       Residual              
  4.01462700990605e-05    3.38848721913166e-06
  4.01893266524972e-05    2.96381572768123e-06
  4.02216637895209e-05    3.25730371476605e-06

200 iterations
Solution process, seconds: 2.747978e+00
}}}

The option -matrix specifies the matrix to solve.  
The initial eigenvectors are generated randomly. 

The matrix file is in a Petsc format.  
These can be setup via some Matlab programs in the PETSc socket interface to Matlab; 
`PetscBinaryRead.m` and `PetscBinaryWrite.m`.  
These programs read and write Matlab matrices and vectors to files formated for Petsc. 
The version from Petsc only supports double.   
We have modified these programs to  also support complex and 64bit integers.  
Our versions are included in the .../blopex_petsc directory along with 
`PetscWriteReadExample.m` to illustrate how to use them. 

The *complex files* are L-matrix-complex_64.petsc (65536x65536 diagonal values 0-4)
and DL-matrix-complex_64.petsc (65536x65536 tridiagonal values 0-4).  

The *complex files* are complex versions of the L and DL double matrices (with imag part zero) 
plus test_complex1_64.petsc (40x40 134 nz hpd random),
test_complex2_64.petsc (1000x1000 50786 nz hpd random) and 
test_complex3_64 (10876 nz hpd random). 