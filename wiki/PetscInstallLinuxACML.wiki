#summary PETSc install with AMD's ACML in Fedora 12

= Introduction =

How To install PETSc with AMD's ACML in Fedora12 64 bit
(assuming bash shell)

= Details =

The basic system info:

uname -a

Linux opt 2.6.31.12-174.2.22.fc12.x86_64 #1 SMP Fri Feb 19 18:55:03 UTC 2010 x86_64 x86_64 x86_64 GNU/Linux

rpm -q openmpi

openmpi-1.3.3-6.fc12.x86_64

rpm -q mpich2

mpich2-1.2.1-2.fc12.x86_64


Download from 
http://developer.amd.com/cpu/Libraries/acml/downloads/pages/default.aspx
the latest ACML libraries, in my case: 
  * http://developer.amd.com/Downloads/acml-4-4-0-gfortran-64bit.tgz
  * http://developer.amd.com/Downloads/acml-4-4-0-gfortran-64bit-int64.tgz

If you use AMD's open64 compiler rather then GNU-FORTRAN/C, you need these: 
  * http://developer.amd.com/Downloads/acml-4-4-0-open64-64bit.tgz
  * http://developer.amd.com/Downloads/acml-4-4-0-open64-64bit-int64.tgz

Install each of them into a SEPARATE local directory, i.e., 
provide different directory names when asked during the installation. 
In my case, the directories are: 
   * /opt/acml-4-4-0-gfortran-64bit
   * /opt/acml-4-4-0-gfortran-64bit-int64
   * /opt/acml-4-4-0-open64-64bit
   * /opt/acml-4-4-0-open64-64bit-int64
correspondingly. 

Each library comes in two different flavours, regular and mp, e.g., 
   * /opt/acml-4-4-0-gfortran-64bit/gfortran64/lib
   * /opt/acml-4-4-0-gfortran-64bit/gfortran64_mp/lib

According to Ch. 2 of the ACML manual, see  
http://developer.amd.com/assets/acml_userguide.pdf
one should use the mp version on a multi-CPU/core nodes. 

However, the PETSc does not currently support the mp version. 
In the notes below, we use the regular version. 
 
The latest ACML may not work on old CPUs! 

Follow http://code.google.com/p/blopex/wiki/openmpiandmpich2switchinFedora12
to set up the MPI, e.g., by running 

module load openmpi-x86_64

Download and extract the latest PETSc, at the moment this is 
ftp://info.mcs.anl.gov/pub/petsc/petsc-lite-3.1.tar.gz 

Extract using *tar xzvf* , cd to PETSc dir and run 

PETSC_DIR=$PWD; export PETSC_DIR

To test the old BLOPEX, run 

./config/configure.py PETSC_ARCH=linux-openmpi-acml-4-4-0-gfortran-64bit --with-blas-lapack-dir=/opt/acml-4-4-0-gfortran-64bit/gfortran64 --download-blopex=1 --download-hypre=1

PETSC_ARCH=linux-openmpi-acml4-4-0-gfortran-64bit; export PETSC_ARCH

make all

To test the latest BLOPEX, instead of using the --download-blopex=1 option,  
follow PetscTestingLinux instructions to test the latest BLOPEX, see 
http://code.google.com/p/blopex/wiki/PetscTestingLinux

Note the Hypre is real and 32-bit-indices only, so an attempt to use 
--download-hypre=1 either with --with-scalar-type=complex or with --with-64-bit-indices would give an error. 


Assuming no errors on the previous steps, run

cd src/contrib/blopex/driver

make driver

Now, you can execute the driver by using 

mpirun -np 2 -x LD_LIBRARY_PATH=/usr/lib64/openmpi/lib:/opt/acml-4-4-0-gfortran-64bit/gfortran64/lib ./driver

Here, both shared libraries /usr/lib64/openmpi/lib and /opt/acml-4-4-0-gfortran-64bit/gfortran64/lib are necessary to specify in the command-line. 
Alternatively, you can set 

LD_LIBRARY_PATH=/usr/lib64/openmpi/lib:/opt/acml-4-4-0-gfortran-64bit/gfortran64/lib; export LD_LIBRARY_PATH

then you can simply run 

mpirun -np 2 ./driver

See http://tldp.org/HOWTO/Program-Library-HOWTO/shared-libraries.html for more info on shared libraries. 

If you get an error like "error while loading shared libraries: /opt/acml-4-4-0-gfortran-64bit/gfortran64_mp/lib/libacml.so: cannot restore segment prot after reloc: Permission denied" it is probably coming from your SELinux security software. Disable SELinux temporarily by running (as root) 

 echo 0 > /selinux/enforce 

After you are done running the codes, restore SELinux by 

echo 1 > /selinux/enforce

If you cannot be root, contact the sysadmin. 


<pre>
Testing the above gives errors, which need to be investigated. 

tar xzvf petsc-lite-3.1.tar.gz
mv petsc-3.1-p2 petsc-3.1-p2-int64-complex-ACML
cd petsc-3.1-p2-int64-complex-ACML
PETSC_DIR=$PWD; export PETSC_DIR 
module load openmpi-x86_64
tar -zxvf ../../blopex_petsc_interface.tar.gz
./config/configure.py PETSC_ARCH=linux-openmpi-acml-4-4-0-gfortran-64bit --with-blas-lapack-dir=/opt/acml-4-4-0-gfortran-64bit/gfortran64  --with-scalar-type=complex --with-64-bit-indices --download-blopex=../../blopex_petsc_abstract.tar.gz
make PETSC_DIR=/home/aknyazev/work/petsc/petsc-3.1-p2-int64-complex-ACML PETSC_ARCH=linux-openmpi-acml-4-4-0-gfortran-64bit all
LD_LIBRARY_PATH=/usr/lib64/openmpi/lib:/opt/acml-4-4-0-gfortran-64bit/gfortran64/lib; export LD_LIBRARY_PATH
make PETSC_DIR=/home/aknyazev/work/petsc/petsc-3.1-p2-int64-complex-ACML PETSC_ARCH=linux-openmpi-acml-4-4-0-gfortran-64bit test
cd src/contrib/blopex/driver
make driver
mpirun -np 2 ./driver

gives 

[0]PETSC ERROR: --------------------- Error Message ------------------------------------
[0]PETSC ERROR: Out of memory. This could be due to allocating
[0]PETSC ERROR: [1]PETSC ERROR: --------------------- Error Message ------------------------------------
[1]PETSC ERROR: Out of memory. This could be due to allocating
[1]PETSC ERROR: too large an object or bleeding by not properly
[1]PETSC ERROR: destroying unneeded objects.
too large an object or bleeding by not properly
[0]PETSC ERROR: destroying unneeded objects.
[1]PETSC ERROR: Memory allocated 10704280784 Memory used by process 7475200
[1]PETSC ERROR: Try running with -malloc_dump or -malloc_log for info.
[1]PETSC ERROR: Memory requested 7160877362979664896!
[1]PETSC ERROR: ------------------------------------------------------------------------
[1]PETSC ERROR: Petsc Release Version 3.1.0, Patch 2, Fri Apr 30 20:23:44 CDT 2010
[1]PETSC ERROR: See docs/changes/index.html for recent updates.
[1]PETSC ERROR: See docs/faq.html for hints about trouble shooting.
[1]PETSC ERROR: See docs/index.html for manual pages.
[1]PETSC ERROR: ------------------------------------------------------------------------
[1]PETSC ERROR: ./driver on a linux-ope named opt by aknyazev Mon May  3 22:52:05 2010
[1]PETSC ERROR: Libraries linked from /home/aknyazev/work/petsc/petsc-3.1-p2-int64-complex-ACML/linux-openmpi-acml-4-4-0-gfortran-64bit/lib
[1]PETSC ERROR: Configure run at Mon May  3 22:22:22 2010
[1]PETSC ERROR: Configure options PETSC_ARCH=linux-openmpi-acml-4-4-0-gfortran-64bit --with-blas-lapack-dir=/opt/acml-4-4-0-gfortran-64bit/gfortran64 --with-scalar-type=complex --with-64-bit-indices --download-blopex=../../blopex_petsc_abstract.tar.gz
[1]PETSC ERROR: ------------------------------------------------------------------------
[1]PETSC ERROR: PetscMallocAlign() line 49 in src/sys/memory/mal.c
[1]PETSC ERROR: PetscTrMallocDefault() line 192 in src/sys/memory/mtr.c
[1]PETSC ERROR: main() line 261 in src/contrib/blopex/driver/driver.c
[0]PETSC ERROR: --------------------------------------------------------------------------
MPI_ABORT was invoked on rank 1 in communicator MPI_COMM_WORLD 
with errorcode 55.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
Memory allocated 10704280784 Memory used by process 7729152
[0]PETSC ERROR: Try running with -malloc_dump or -malloc_log for info.
[0]PETSC ERROR: Memory requested 7160877362979664896!
[0]PETSC ERROR: ------------------------------------------------------------------------
[0]PETSC ERROR: Petsc Release Version 3.1.0, Patch 2, Fri Apr 30 20:23:44 CDT 2010
[0]PETSC ERROR: See docs/changes/index.html for recent updates.
[0]PETSC ERROR: See docs/faq.html for hints about trouble shooting.
[0]PETSC ERROR: See docs/index.html for manual pages.
[0]PETSC ERROR: ------------------------------------------------------------------------
[0]PETSC ERROR: ./driver on a linux-ope named opt by aknyazev Mon May  3 22:52:05 2010
[0]PETSC ERROR: Libraries linked from /home/aknyazev/work/petsc/petsc-3.1-p2-int64-complex-ACML/linux-openmpi-acml-4-4-0-gfortran-64bit/lib
[0]PETSC ERROR: Configure run at Mon May  3 22:22:22 2010
[0]PETSC ERROR: Configure options PETSC_ARCH=linux-openmpi-acml-4-4-0-gfortran-64bit --with-blas-lapack-dir=/opt/acml-4-4-0-gfortran-64bit/gfortran64 --with-scalar-type=complex --with-64-bit-indices --download-blopex=../../blopex_petsc_abstract.tar.gz
[0]PETSC ERROR: ------------------------------------------------------------------------
[0]PETSC ERROR: PetscMallocAlign() line 49 in src/sys/memory/mal.c
[0]PETSC ERROR: PetscTrMallocDefault() line 192 in src/sys/memory/mtr.c
[0]PETSC ERROR: main() line 261 in src/contrib/blopex/driver/driver.c
--------------------------------------------------------------------------
mpirun has exited due to process rank 1 with PID 14390 on
node opt exiting without calling "finalize". This may
have caused other processes in the application to be
terminated by signals sent by mpirun (as reported here).
--------------------------------------------------------------------------
[opt:14388] 1 more process has sent help message help-mpi-api.txt / mpi-abort
[opt:14388] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
</pre>
